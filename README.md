# PM-INR: Prior-Rich Multi-Modal Implicit Large-Scale Scene Neural Representation (AAAI24, oral)

*Yiying Yang*, *Fukun Yin*, *Wen liu*, *Jiayuan Fan†*, *Xin Chen*, *Gang Yu*, *Tao Chen*


*†Corresponding author*



We propose an effective implicit neural representation pipeline to cope with the cubically growing sampling space of outdoor unbounded large-scale scenes by extracting rich priors from multi-modal inputs and equipping sampling regions. A multi-modal prior fusion module is proposed to ensure scene cross-modal consistency while enriching regional feature representations. Extensive experiments demonstrate that our PM-INR outperforms state-of-the-art methods, including robustness to large-scale outdoor scene representation and the capability to synthesize more photo-realistic novel views. Our code and models will be available.

![image](https://github.com/YiyingYang12/PM-INR/blob/main/Pipeline.png)
